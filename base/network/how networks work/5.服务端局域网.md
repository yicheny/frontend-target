[TOC]

互联网 -> POP -> 接入网 -> 局域网路由器 -> 公司内网

在很久以前服务器端和客户端的局域网没什么区别，都是从路由器直接和公司内网相连接的，不过这种做法有几个问题：
1. 一个是IP地址不足，在前面已经说过【可是这个不是能通过路由器解决？】
2. 安全问题，可以直接访问到内网【可是路由器也可以进行包过滤啊，艹】

有两种做法，第一个是部署防火墙，防火墙是啥先不用管，这里只需要知道防火墙可以进行包过滤，一定程度上可以保证网络访问的安全即可。

第二个是部署在运营商数据中心，公司可以购买运营商的服务器，有很多好处：
1. 运营商服务器通常是和IX、NOC直连的，速度要比局域网服务器快很多
2. 运营商服务器放在专门的设施中，防火防震放断电，24小时不断电，而且有24小时门禁，可以说安全性比一般公司自己部署服务器安全的多。另外运营商服务器还提供防火墙配置、服务器工作状态监控、非法入侵监控等，从网络安全上来说比自己搞要专业的多。

# 防火墙
防火墙是什么？它是用于防护服务安全的一种软件或硬件，主要作用就是只允许发送特定请求对特定应用程序进行访问

在实际部署中中，公司内网和服务器是分开部署的，公司内网按照我们之前的规则进行包过滤和地址转换。

而服务器通常是单独部署的，这里需要使用防火墙保护其安全，防火墙有很多种策略，最常见、性价比最高的就是包过滤方案。

相比于路由器自带的包过滤功能，防火墙的包过滤功能更加强大，也更加专业，通常会提供日志记录功能，如果你不需要这些功能，实际上用路由器自带的包过滤功能充当防火墙也是可以的，因为事实上，防火墙就是因为路由器自身的包过滤功能不够强大，所以才能独立出性能更好、功能更多、更专业的软件或硬件作为防火墙。

下面简单说一下包过滤防火墙的功能，它可以通过MAC、IP、TCP、UDP、ICMP等协议相关字段控制过滤。

比如说我们想限制：允许互联网请求服务器，但是不允许服务器请求互联网，这一需求是因为有些病毒是感染式的，通过这种方式可以一定程度放置服务器的病毒感染互联网的病毒。

最直接的话我们肯定是想直接禁止服务器向外发送请求，然后这并不可行，因为TCP阶段必须要建立连接，发送响应信息，如果直接禁止服务器发送请求，那么无法响应信息，那么外部也不能对服务器做请求了。

那么要怎么做呢？其实很简单，TCP的控制字段中有个SYN位，如果SYN为1，表示主动向外发送请求，而如果是其他情况，比如说响应信息，这个控制位都是0。所以我们只需要在包过滤规则中限制SYN=1的请求发送，就可以实现服务器不能主动向外发送请求，但是可以响应外部的请求。

另一方面，我们还希望限制互联网对服务器的访问，如果不做任何设置，那么现在互联网是可以访问服务器的所有端口的，假设通过服务器的某个端口可以访问到内部文件，那么这就有可能造成风险，所以这里我们可以进一步限制，限制端口，其实本质是限制程序，因为服务器上可能只有1、2个程序是对外开放的，剩下的都是内部程序，以及私有文件，我们不希望外部访问。

所以我们可以通过限制端口的方式，限制互联网对服务器应用程序的访问。

防火墙一定程度上保护了服务器的安全，但是对某些危险还是难以涉及，最典型的是请求数据，访问墙不会对数据进行校验，服务器程序可能执行某些特定数据时会出现宕机或错误，这本质上是程序的bug造成的。

针对这一类问题，有两个方案，第一个是修复程序bug，第二个是安装可以检查风险数据的软件。

但即使如此也不是万无一失，因为以上两个方案只能针对已知的bug，难以防御的是为止的bug问题，这种我们是无能为力的，目前来说只能开发这自己多做测试多思考了。

# 负载均衡
在现代计算机网络应用中，通过一个网页应用会被许多个客户同时访问，如此一来就可能出现问题，问题通常出现在两个方面：
1. 网络堵塞
2. 服务器性能不足

针对问题可以使用加大带宽或升级高性能服务器的方案，不过如果访问量更大一些，这两个方案也不足以应对，通常另一种方案更加有效，即采用多台服务器共同运行，以减轻带宽和运算方面的压力，这种部署服务器的架构叫做分布式。

最简单的方案是通过DNS，比如说针对一个网址，我们在DNS上注册多台服务器，让它轮询返回。

这种方案存在明显缺陷，比如如果某台服务器宕机了，DNS还是会发送宕机的ip，比如即使是轮询返回也不能保证每台服务器的算力使用情况相同，根据请求和服务器本身的不同，一些服务器可能已经满负荷了，另一些服务器算力空闲也是很有可能的，DNS难以针对服务器的负载情况发送消息。

因而，使用DNS轮询ip的方式不是一个很好的方案。

更合理的方案是负载均衡，具体做法是将负载均衡服务器作为目标网址的服务器注册到DNS中，当请求需要访问网址时，返回负载均衡服务器的ip，然后负载均衡服务器会连接和监控多台实际负责业务的服务器，根据服务器的运行情况，将请求转发给合适的业务服务器。

这里需要注意一个问题，在现代网络应用中，有一些http请求是具有关联性的，这一类必须发送到同一台服务器上。

但是http设计上是无关联网络协议，并不能知道哪些http请求是具有关联性的。

这和http的诞生场景有关，在http设计之初，就是用于传递一些静态文件，本来就不需要有关联，如果设计额外的关联控制字段，则需要传递额外的数据，这对网络来说是额外的负担。

然后网络应用发展迅速，现在我们已经可以通过网页实现很复杂的应用了，为此我们需要在http中体现其关联。

这里有2种方式传递关联信息，通过http字段进行扩展，或者放在表单数据中，这种用于表示http关联信息的数据我们称之为cookie。

# 代理
## 缓存代理
除了以上负载均衡方案之外，还有另一种有效方案，即缓存代理。

有些请求是无副作用的，任何时候请求结果都一样，只是运算过程或数据提取非常麻烦，这一类请求是可以进行缓存的。

有些请求对时间要求没那么高，比如说一些静态页面、静态文件，迟几分钟更新没有关系，这一类也可以进行缓存。

另一些必须时间提取数据运算的请求是不能缓存，不过即使只有部分请求可以缓存，也会有效的减轻服务器压力和提升请求速度。

缓存代理和负载均衡设置上很像，也是将ip设置到DNS里，请求时会发送到缓存代理上，如果有缓存，则直接返回缓存。

如果没有，则请求业务服务器，并添加字段via，表示这是经过代理服务器转发的请求。

业务服务器进行处理，然后响应请求，如果有via字段，则将数据发送给代理服务器，代理服务器将数据添加到缓存，同时将响应返回给客户端。

另一点需要注意的是缓存时间，缓存并不是永久有效的，需要设置一个更新时间，在更新时间到达后会进行请求更新缓存。

## 正向代理
在客户端设置代理的方式叫做正向代理，也叫代理。实际上一开始代理这个词就是说正向代理，只是后来出现了许多其他代理，所以才为了区分叫做正向代理。

正向代理做法是在客户端浏览器设置代理服务器，无论做什么请求都直接将请求发给代理服务器。

这种做法问题很大，首先是因为需要设置浏览器，我们可以对自己的浏览器进行设置，但是很难对客户的浏览器也进行设置【另一个问题是，如果要换代理，就很麻烦了】

然后，对浏览器的设置可能导致浏览器出错，导致浏览器无法上网的可能也是存在的。

## 反向代理
总的来说，正向代理方案存在许多问题，所以后来才出现了反向代理，即针对部分特定网址进行转发的服务器。

## 透明代理
透明代理兼顾了正向代理和反向代理的优点。

透明代理不需要设置浏览器，同时也不需要将ip绑定到网址上，事实上也不能这么做，因为透明代理之所以将透明代理就是在发送过程中感受不到其存在，如果将网址和ip绑定，那么透明代理本身就称为了访问目标，这一定程度了限制了很多东西。

那么透明代理要怎么做呢？答案是在请求的过程中拦截请求，然后转发。

因为透明代理的这一实现模式，所以必须放在请求的必经之路上，通常来说，接入网入口就是一个好的选择，很多透明代理就是设置在接入网入口的。